# @package dataset
defaults:
  - /dataset/default
_target_: lightning_transformers.core.nlp.HFDataModule
cfg:
  # load dataset from HF hub
  dataset_name: null
  dataset_config_name: null
  # load dataset from local files
  train_file: null
  validation_file: null
  test_file: null
  # train test split
  train_val_split: null
  limit_train_samples: null
  limit_val_samples: null
  limit_test_samples: null
  # tokenizer
  padding: "max_length"
  truncation: "only_first"
  max_length: 128
  max_length_pctl: null
  # hf datasets map
  preprocessing_batch_size: ${training.preprocessing_batch_size}
  preprocessing_num_workers: ${training.preprocessing_num_workers}
  load_from_cache_file: True
  cache_dir: null
  # obsolete
  max_samples: null
